<html>
  <head>
    <meta charset="UTF-8" />
    <title>《自画像：30岁，在激情和困顿间摇摆》</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.4.0/p5.min.js"></script>
    <script src="https://unpkg.com/ml5@0.4.3/dist/ml5.min.js"></script>
  </head>
  <style>
    body {
      background: red;
    }
    h1 {
      text-align: center;
    }
  </style>
  <body>
    <script>
      let faceapi;
      let video;
      let detections;
      let capture;
      let count = 0;
      let cnv;

      // by default all options are set to true
      const detection_options = {
        withLandmarks: true,
        withDescriptors: false,
        MODEL_URLS: {
          Mobilenetv1Model:
            "https://ml5-1254453785.cos.ap-guangzhou.myqcloud.com/faceapi/ssd_mobilenetv1_model-weights_manifest.json",

          FaceLandmarkModel:
            "https://ml5-1254453785.cos.ap-guangzhou.myqcloud.com/faceapi/face_landmark_68_model-weights_manifest.json",
          FaceLandmark68TinyNet:
            "https://ml5-1254453785.cos.ap-guangzhou.myqcloud.com/faceapi/face_landmark_68_tiny_model-weights_manifest.json",
          FaceRecognitionModel:
            "https://ml5-1254453785.cos.ap-guangzhou.myqcloud.com/faceapi/face_recognition_model-weights_manifest.json"
        }
      };
      function setup() {
        cnv = createCanvas(720, 1080);
        cnv.position((windowWidth - width) / 2, (windowHeight - height) / 2);
        background("black");
        capture = createCapture(VIDEO);
        capture.size(width, height);
        capture.hide();
        faceapi = ml5.faceApi(capture, detection_options, modelReady);
      }

      function modelReady() {
        console.log("ready!");
        console.log(faceapi);
        faceapi.detect(gotResults);
      }

      function gotResults(err, result) {
        count += 1;
        if (err) {
          console.log(err);
          return;
        }
        detections = result;
        if (detections) {
          if (count % 1 == 0) {
            drawLandmarks(detections);
          }
        }
        faceapi.detect(gotResults);
      }

      function drawLandmarks(detections) {
        // push();
        // fill("red");
        // noStroke();
        // rectMode(CENTER);
        // square(width / 2, height / 2, width / 4);
        // pop();

        noFill();
        strokeWeight(5);
        // stroke("red")
        stroke(random(["red", "black"]));
        // stroke(color(count % 255, 0, 0));

        for (let i = 0; i < detections.length; i++) {
          const mouth = detections[i].parts.mouth;
          const nose = detections[i].parts.nose;
          const leftEye = detections[i].parts.leftEye;
          const rightEye = detections[i].parts.rightEye;
          const rightEyeBrow = detections[i].parts.rightEyeBrow;
          const leftEyeBrow = detections[i].parts.leftEyeBrow;
          const jawOutline = detections[i].parts.jawOutline;
          drawPart(mouth, true);
          drawPart(nose, false);
          drawPart(leftEye, true);
          drawPart(rightEye, true);
          drawPart(leftEyeBrow, false);
          drawPart(rightEyeBrow, false);
          drawPart(jawOutline, false);
        }
      }

      function drawPart(feature, closed) {
        push();
        let portion = (count % 255) / 255;
        portion = 1;
        scale(1 + portion, 1);
        translate((-width * portion) / 4, 0);
        translate(width, 0);
        scale(-1, 1);
        beginShape();
        for (let i = 0; i < feature.length; i++) {
          const x = feature[i]._x;
          const y = feature[i]._y;
          vertex(x, y);
        }

        if (closed === true) {
          endShape(CLOSE);
        } else {
          endShape();
        }
        pop();
      }
    </script>
  </body>
</html>
